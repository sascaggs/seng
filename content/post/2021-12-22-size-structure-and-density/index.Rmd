---
title: "Network size and structure"
author: Shane A. Scaggs
date: '2021-12-22'
slug: size-structure-and-density
categories:
  - theory
tags:
  - edges
  - nodes
  - structure
  - simulation
  - scale
---

```{r, message=F, echo=F, warning=F}
library(igraph)
library(statnet)
library(tidygraph)
library(ggraph)
library(tidyverse)
library(ggprism)
library(patchwork)

prickles <- theme(panel.background = element_rect(fill='white', color='black', size=2),
                  axis.ticks.length = unit(0.2, 'in'), 
                  panel.grid = element_blank(),
                  prism.ticks.length = unit(0.15, 'in'), 
                  text = element_text(family='mono', size=13))

set.seed(100)
```


The size of a network is determined by the number of vertices and edges within it, and different size networks have different structural properties. This is obviously true if social processes like homophily, preferential attachment, or triadic closure influence network size, but it is also true for randomly generated networks. 

How do properties like density, sparseness, degree distribution, or connectivity change as the number of vertices in a network increases? To find out, I set up a few computational experiments for directed and undirected networks. 

# Sparse networks 

A graph is considered sparse if the number of edges, $m$, is less the number of vertices, $n$; a value given by $m < O(n)$, the orthogonal group. As the number of vertices increases, the density at which a network is considered sparse decreases.  Additionally, this negative relationship   differs for undirected and directed networks, because the maximum edges in a directed graph is given by $n(n-1)$ whereas in an undirected graph, it is $n(n-1)/2$. 

Generally speaking, the point at which any network becomes sparse ($S$) is the ratio between the orthogonal set and the maximum number of possible edges. For a directed network, this is given by:

$$S = \frac{O(n)}{n(n-1)}$$ 

And for an undirected network: 

$$S = \frac{O(n)}{n(n-1)/2}$$

So if we vary $n$ and plot the value of $S$, we can see how this threshold changes for different size networks. Here is a function to do this: 

```{r}
sparsepoint <- function(n, directed=F) {
  if ( directed == F  )   { n / (n*(n-1)/2) }
  else if ( directed == T ) { n / (n*(n-1))   }
  else { 
    print('Must be TRUE or FALSE.')
  }
}
```
```{r}
sparsepoint(100)
sparsepoint(100, directed = T)
```

Now we can create a sequence of $n$ values and graph the results. Figure 1 shows what this function looks like as $n$ increases from `1` to `10000`. When a network is smaller than `1000` vertices, the sparsepoint is occurs  between `0.5%` and `2%` density. The dropoff occurs more slowly for undirected networkss. Above `1000` vertices, the sparsepoint for both directed and undirected networks begins to converge on `0.01%` density.

```{r, echo=F, fig.height=4, fig.width=6, fig.cap='The density at which a network is considered sparse as a function of the number of vertices.'}
Nseq <- seq(1,10000, by=99)
tibble(di = sparsepoint(Nseq, directed = T), 
       un = sparsepoint(Nseq), 
       Nseq) %>%
  gather(key=key, value=value, -Nseq) %>%
  ggplot(aes(x=Nseq)) + 
  prickles + 
  geom_line(aes(y=value, color=key), lwd=0.8) + 
  scale_x_continuous(guide = 'prism_minor', 
                     breaks = seq(0,10000,2000)) + 
  scale_y_continuous(guide = 'prism_minor', 
                     breaks = seq(0,0.02,0.005)) + 
  theme(legend.key = element_rect(fill='white')) + 
  scale_color_manual(values = c('cyan','magenta'), labels = c('directed','undirected')) + 
  labs(x='n', y='S', color=NULL)
```

# Degree distribution

For a network of any size, as the edge density increases, the degree distribution is expected to become more uniform, with the mean degree starting to approximate $n$. To see how degree distribution changes with edge density, we can calculate degree for each node across a variety of density levels. Here I do this for networks with `10`, `75`, and `150` vertices, each ranging in density from `0.01` to `0.99`. 

```{r}
d <- seq(0.01,0.99, length.out=11)
l <- list()
for(i in seq_along(d)) {
  l[[i]] <- network(10, directed = F, density = d[i])
  m <- data.frame(lapply(l, degree))
}
colnames(m) <- paste0('Density',d)
head(m)
```
I do this for each network size and then plot the distributions to compare.

```{r, echo=F, message=F, warning=F, fig.height=9.6, fig.width=8.4, fig.cap='A comparison of the degree distributions at increasing levels of density for three different size networks.'}
d <- seq(0.01,0.99, length.out=11)
l <- list()
for(i in seq_along(d)) {
  l[[i]] <- network(10, directed = F, density = d[i])
  m <- data.frame(lapply(l, degree))
}
colnames(m) <- paste0('Density',d)

p1 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  stat_ecdf(aes(color=key), size=2, alpha=0.5) + 
  prickles  + theme(legend.position = 'none') +
  labs(x='Degree',y='Cumulative density', title='10 vertices') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9, 
                             labels = paste(d))  


p2 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  geom_density(aes(color=key), size=1.2, alpha=0.5) +
  prickles + theme(legend.position = 'none') + 
  labs(x='Degree', y='Density', color='Edge\ndensity') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9, 
                             labels = paste(d))  

l <- list()
for(i in seq_along(d)) {
  l[[i]] <- network(75, directed = F, density = d[i])
  m <- data.frame(lapply(l, degree))
}
colnames(m) <- paste0('Density',d)

p3 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  stat_ecdf(aes(color=key), size=2, alpha=0.5) + 
  prickles  + theme(legend.position = 'none') +
  labs(x='Degree',y='Cumulative density', title='75 vertices') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9)  


p4 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  geom_density(aes(color=key), size=1.2, alpha=0.5) + 
  prickles  + 
  labs(x='Degree', y='Density', color='Edge\ndensity') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9, 
                             labels = paste(round(d, digits = 2)))  


l <- list()
for(i in seq_along(d)) {
  l[[i]] <- network(150, directed = F, density = d[i])
  m <- data.frame(lapply(l, degree))
}
colnames(m) <- paste0('Density',d)

p5 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  stat_ecdf(aes(color=key), size=2, alpha=0.5) + 
  prickles  + theme(legend.position = 'none') +
  labs(x='Degree',y='Cumulative density', title='150 vertices') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9)  


p6 <- m %>% gather() %>%
  ggplot(aes(value)) + 
  geom_density(aes(color=key), size=1.2, alpha=0.5) + 
  prickles  + theme(legend.position = 'none') +
  labs(x='Degree', y='Density', color='Edge\ndensity') + 
  scico::scale_color_scico_d(palette = 'hawaii', end=0.9, 
                             labels = paste(d))  

(p1 + p2) / (p3 + p4) / (p5 + p6)

```

The degree distributions of networks that have only a couple hundred vertices or less can overlap quite a bit across different levels of edge density. Large networks have a much more precise degree distribution. This makes it clear why descriptive statistics that depend on density cannot easily be compared between different networks, unless the networks are large.

# Average Path Length 

The length of a path between two vertices is determined by the number of vertices that lie between them. A direct path between two vertices is equal to `1`. 

We observed that as $m$ increases, mean degree approaches $n$. We can expect that when mean degree is approximately $n$, the average path length should be approximately `1`. 

The function below accepts a sequence of densities and a number of vertices, and returns the mean degree and average path length at each level of density. 

```{r}
l <- list()
apl <- c()

DegApl <- function(n, directed = F, d, seed=777) {
  for(i in seq_along(d)) {
    l[[i]] <- network(n, directed = directed, 
                      density = d[i], seed=seed)
    m <- data.frame(lapply(l, degree))
    k <- lapply(l, geodist, inf.replace = 0, count.paths = F)
    apl[i] <- mean(k[[i]]$gdist)
  }
  remove(l,k) 
  colnames(m) <- c(1:length(d))
  mD <- apply(m, 2, mean)
  return(cbind(apl,mD,n,d))
}
```

Now we can explore relationships between these variables by running this function on networks with different sizes. Here we use a long sequence of densities to better approximate relationships.

```{r, echo=F, warning=F, message=F}
dseq <- seq(0.01,0.99, length.out=20)

df <- as.data.frame(rbind(
  DegApl(10,  directed = F, d = dseq), 
  DegApl(75,  directed = F, d = dseq), 
  DegApl(150, directed = F, d = dseq)
))
```

We can expect that mean degree and density are positively correlated. But what is the shape of this relationship? 

```{r, echo=F, fig.height=3.3, fig.width=4.8, fig.cap='The association between edge density and mean degree is approximately linear.'}
df %>% ggplot(aes(d, mD)) + 
  geom_line(aes(color=as.factor(n)), size=1.2) + 
  prickles + theme(legend.key = element_rect(fill='white')) + 
  scico::scale_color_scico_d(palette = 'devon', end=.85) + 
  labs(x='Edge density (d)',y='Mean degree (mD)', color='n')
```

Average path length should also systematically vary with density, but it is unclear what the shape of this relationship will look like. For instance, at low density, many paths = `0` because the many vertices are isolated. However, density networks should have short paths, as most vertices are directly connected to each other. 

```{r, echo=F, fig.height=3.3, fig.width=4.8, fig.cap='Explosive percolation of average path length'}
df %>% ggplot(aes(d, apl)) + 
  geom_line(aes(color=as.factor(n)), size=1.2) + 
  prickles + theme(legend.key = element_rect(fill='white')) + 
  scico::scale_color_scico_d(palette = 'devon', end=.85) + 
  labs(x='Edge density (d)',y='Average path length (apl)', color='n')
```

At very low density (`0.01`), the average path length is essentially `0`, but just a small increase in density leads to explosive increase in the average path length. This phenomenon is known as *explosive percolation*, and it occurs because even randomly added edges have a chance of connected isolate vertices to one large component. 

This explosion happens even sooner for networks with a greater number of vertices. But, exactly when does this percolation happen? At the `sparsepoint` (!) which we know varies systematically as a function of $n$. Because the density at which a network goes from being sparse to not sparse decreases as a function of network size, we see explosive changes in average path length sooner and sooner as network size increases. 

As we continue to increase density, the average path length decreases because the number of direct paths between vertices that are part of the largest component continues to increase, and this drives down the average path length. Eventually the average path length for networks of all sizes converges on `1`. 
